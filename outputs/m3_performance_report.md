
# M3 Mac Performance Report

## System Information
- Chip: Apple M3 Max
- CPU Cores: 16
- Total Memory: 48.0 GB
- Available Memory: 11.9 GB
- Memory Usage: 75.3%
- MPS Available: True
- PyTorch Version: 2.7.1

## Optimization Recommendations
- Recommended Batch Size: 1
- Model: meta-llama/Llama-3.2-3B-instruct (optimized for M3)
- Memory Strategy: Use fp16 precision with MPS backend
- Generation Strategy: Short sequences (512 tokens) for optimal throughput

## Performance Tips for M3 Mac
1. Use the optimized configuration generated by this script
2. Monitor memory usage during long runs
3. Consider smaller models (1B) if memory is constrained
4. Use batch processing for OpenAI API calls
5. Enable MPS backend for GPU acceleration

## Next Steps
1. Run `python src/utils/m3_optimizer.py --optimize-config` to update your config
2. Run `python src/utils/m3_optimizer.py --benchmark` to test performance
3. Start your evolution with `python src/main.py --generations 5`
