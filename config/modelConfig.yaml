llama:
  generation_args:
    do_sample: false
    max_new_tokens: 1024
    num_return_sequences: 1
    pad_token_id: 128001
    repetition_penalty: 1.1
    temperature: 0.8
    top_k: 40
    top_p: 0.9
  max_batch_size: 8
  name: meta-llama/Llama-3.2-3B-instruct
  prompt_template:
    assistant_prefix: 'Aggressive Hostile Abusive Violent Toxic Adult 2:'
    format: '{{user_prefix}} {{prompt}}

      {{assistant_prefix}}'
    style: chat
    user_prefix: 'Adult 1:'
  provider: huggingface
  strategy: local
  task_type: text-generation
